---
title: "A web scraper tutorial using R packages `httr` and `rvest`"
author: "Luis M. Avila"
date: "10/30/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

I this tutorial we will learn:  

* How to get (download) a website using the `httr` package
* How to parse html using the `rvest` package
* How to use html forms with the `httr` package
* Transforming out parsed data into a tidy table

For a web scraping example I will use a table of exchange rates (peruvian soles to US dollars) from Peru's tax agency SUNAT. Today (someday of Oct 2017) that page looked like this:


![](sunatPage.png)

### 1. Loading the libraries and downloading a website
```{r, message=FALSE, warning=FALSE}
 library(httr)  # will be use to make HTML GET and POST requests
 library(rvest) # will be used to parse HTML
 library(tidyr) #will be used to remove NA


 url <- 'http://www.sunat.gob.pe/cl-at-ittipcam/tcS01Alias'
 
 website1 <- GET(url) #it also gets the cookies that httr will mantain
#cookies(r)
 print(content(website1))
 
```

### 2. Getting information from a website with `html_nodes` from the `rvest` package
We get the webpage title and tables with `html_nodes` and labels such as `h3` which was used for the title of the website and `table` used for the tables.
```{r}


  titles <- html_nodes(content(website1), "h3")
  print(html_text(titles)[[1]])
   
  tbls <- html_nodes(content(website1), "table")
  print(length(tbls))
  
```



We can see that there are 6 tables. But through trial and error I find that my table of interest is table 2.



```{r}
  tbl2<-html_table(tbls[[2]],fill=TRUE)
  print(tbl2)
  
```  
  
## 3. Downloading  data from past months using html forms
If we examine the source code of the website we will find that it uses html forms to pass month and year information to show past reports. The form method used is `POST`. We will prepare a query with the fields of the form and submit that info with `POST` function from `httr`.

This page we are using is in spanish and the fields of the form are called "anho" (a aproximation of the spanish word for year) and "mes" (spanish for month). We will request data for October (10) of 2017.
Again, we web html as reponse.

```{r}
query <- list('mes'="10",
    'anho'="2017"
    )
website2<-POST(url, body = query,encode = "form")
print(content(website2))
titles <- html_nodes(content(website2), "h3")
print(html_text(titles)[[1]])
```

And we can get the title of the page and our table of interest for that month.
```{r}

tbls <- html_nodes(content(website2), "table")
print(length(tbls))
tbl2<-html_table(tbls[[2]],fill=TRUE)
print(tbl2)


```

## 4. Reformatting the data into a  tidy data.frame

```{r}
  
  num.cols<-dim(tbl2)[2]
  num.rows<-dim(tbl2)[1]
  print(dim(tbl2))
```


We already have the number of rows and columns and we used them to create vectors that we then integrate into a data.frame

```{r}
  dia<-c() #will store day numbers
  compra<-c() # will store purchase price
  venta<-c()  # will store sell price

  for(i in 2:num.rows){
     for(j in 1:(num.cols/3)){
        dia<-c(dia,as.numeric(tbl2[i,(j-1)*3+1]))
        compra<-c(compra,as.numeric(tbl2[i,(j-1)*3+2]))
        venta<-c(venta,as.numeric(tbl2[i,(j-1)*3+3]))
     }
  }
  
  pen.oct.2017<-data.frame(dia,compra,venta)
  pen.oct.2017<- pen.oct.2017 %>% drop_na() #dropping NA (not available) values
  print(pen.oct.2017,row.names = FALSE)
  
```
